# -*- coding: utf-8 -*-
"""NLP Exercise 1 (zipf's).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IvZcqrttYeNOTcM7ALm8luvTCMFIvrp3
"""

import urllib.request
from collections import Counter
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# text/data
book_url_es = 'https://www.gutenberg.org/cache/epub/51569/pg51569.txt' #Spanish book of poems by Rubén Dario
book_url_en = 'https://www.gutenberg.org/files/1321/1321-0.txt' #English book of poems by T.S. Eliot

#PREPROCESSING DATA
# to read a text from a URL
def read_from_txt(book_url):
  book_text = urllib.request.urlopen(book_url)
  book_text = book_text.read() 
  book_text = book_text.decode("utf-8") 
  return book_text

# to remove unnecessary parts of the file
# the file contains some description at the start and end of the file
def clean_poems(data):
  clean_poem = data.split('*** END')[0] #removing the unnecesary part at the end of the file
  clean_poem = clean_poem.split(' ***')[1] #removing the unnecesary part at the beginning of the file
  return clean_poem

# to remove punctuations and unnecessary characters (e.g. \r,\r\n)
def remove_punctuation(data):
  chars_to_remove = "!\“#$%&'()*+,-./:;<=>?@[\]^_`{|}~0123456789\r\n"
  without_punctuation = str.maketrans("", "", chars_to_remove)
  remove_punctuation = data.translate(without_punctuation)
  return remove_punctuation

# to tokenize (split by whitespace) and normalize (turn into lowercase) the text
def tokenized_poems(data):
  word_tokenized_book = data.split(' ')
  word_tokenized_normed_book = [w.lower() for w in word_tokenized_book]
  return word_tokenized_normed_book

#PROCESSING DATA
# to count the frequency of words in the text
def count_frequency(data):
  freq = Counter(data)
  return freq

# to count the length of each word in the text
def count_word_length(data):
  words = []
  length = []
  for key in data.keys():
      words.append(key)
  for item in words:
      length.append(len(item))
  return length

#VISUALIZATION
# to create data frame
def dataframe(data):
  df = pd.DataFrame.from_records(list(dict(data).items()), columns=['word','frequency'])
  df['number of characters'] = length
  df = df.sort_values(by=['frequency'], ascending=False)
  df['rank'] = list(range(1, len(df) + 1))
  return df

# to create chart between rank and frequency of words
def create_chart(data):
  chart = sns.relplot(x="rank", y="frequency", data=data)
  return chart

def main():
  # read text, remove unnecessary parts, remove punctuations, tokenize, and normalize
  book_text_en = read_from_txt(book_url_en)
  clean_book_text_en = clean_poems(book_text_en)
  print(clean_book_text_en)
  print(len(clean_book_text_en))
  clean_book_without_punct_en = remove_punctuation(clean_book_text_en)
  print(clean_book_without_punct_en)
  word_tokenized_normed_book_en = tokenized_poems(clean_book_without_punct_en)
  print(len(word_tokenized_normed_book_en))
  book_text_es = read_from_txt(book_url_es)
  clean_book_text_es = clean_poems(book_text_es)
  print(clean_book_text_es)
  print(len(clean_book_text_es))
  clean_book_without_punct_es = remove_punctuation(clean_book_text_es)
  print(clean_book_without_punct_es)
  word_tokenized_normed_book_es = tokenized_poems(clean_book_without_punct_es)
  print(len(word_tokenized_normed_book_es))

  # count the frequency of words
  freq_book_en = count_frequency(word_tokenized_normed_book_en)
  print(freq_book_en)
  freq_book_es = count_frequency(word_tokenized_normed_book_es)
  print(freq_book_es)

  # count the length of each word
  length_en = count_word_length(freq_book_en)
  length_es = count_word_length(freq_book_es)

  # put data into dataframe
  df_en = dataframe(freq_book_en)
  df_en = df_en.drop(index=0) #to remove whitespace frequency from rank
  df_en['rank'] = list(range(1, len(df_en) + 1))
  print(df_en)
  df_es = dataframe(freq_book_es)
  df_es = df_es.drop(index=24) #to remove whitespace frequency from rank
  df_es['rank'] = list(range(1, len(df_es) + 1))
  print(df_es)

  # to save the dataframe, if needed
  df_en_file = df_en.to_csv('df_en.csv')
  df_es_file = df_es.to_csv('df_es.csv')

  # create chart
  chart_en = create_chart(df_en)
  print(chart_en)
  chart_es = create_chart(df_es)
  print(chart_es)
main()

